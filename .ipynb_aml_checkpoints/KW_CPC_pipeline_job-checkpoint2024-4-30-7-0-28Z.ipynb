{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), \"e1f27d73-68d8-4f59-900b-77783d4c5b3b\", \"End2EndCPC\", \"End2End_CPC\"\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1717052160617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "src folder created\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052162112
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/prepare-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "def main(args):\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    imputed_data = impute(df)\n",
        "\n",
        "    scaled_data = scale_data(imputed_data)\n",
        "\n",
        "    output_df = scaled_data.to_csv((Path(args.output_data)), index = False)\n",
        "\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    print(f'Preparing {df.shape[1]} columns and {df.shape[0]} rows of data')\n",
        "    \n",
        "    return df\n",
        "\n",
        "def impute(df):\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype in ['float64', 'int64']:\n",
        "            fill_value = df[column].median()\n",
        "        else:\n",
        "            fill_value = df[column].mode()[0]\n",
        "        \n",
        "        df[column].fillna(fill_value, inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def scale_data(df):\n",
        "    scaler = RobustScaler()\n",
        "    num_cols = df.select_dtypes(['float64', 'int64']).columns.to_list()\n",
        "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_data\", dest='output_data',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    args = parse_args()\n",
        "\n",
        "    main(args)\n",
        "\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/prepare-data.py\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/train-model.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import glob\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    mlflow.autolog()\n",
        "\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = split_data(df,args.target_feature)\n",
        "\n",
        "    model = train_model(args.algorithm, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    print(f'Modeling with {df.shape[1]} columns and {df.shape[0]} rows of data')\n",
        "    \n",
        "    return df\n",
        "\n",
        "def split_data(df,target_feature):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df.drop(target_feature,axis=1), np.ravel(df[target_feature])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, random_state=99)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def train_model(algorithm,X_train, X_test, y_train, y_test):\n",
        "    print(\"Training model...\")\n",
        "    if algorithm == \"gradient-boosting\":\n",
        "        model = GradientBoostingRegressor()\n",
        "    if algorithm == \"random-forest\":\n",
        "        model = RandomForestRegressor()\n",
        "    else:\n",
        "        model = LinearRegression()\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    mlflow.sklearn.save_model(model, args.model_output)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def eval_model(model, X_test, y_test):\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = mean_squared_error(y_pred, y_test)\n",
        "    print('RMSE:', rmse)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--algorithm\", dest='algorithm',\n",
        "                        type=str, default='linear-regression')\n",
        "    parser.add_argument(\"--target_feature\", dest='target_feature',\n",
        "                        type=str, default='CPC')\n",
        "    parser.add_argument(\"--model_output\", dest='model_output',\n",
        "                        type=str)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    return args\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    args = parse_args()\n",
        "\n",
        "    main(args)\n",
        "\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting src/train-model.py\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prepare-data.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: prep_data\n",
        "display_name: Prepare training data\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  input_data: \n",
        "    type: uri_file\n",
        "outputs:\n",
        "  output_data:\n",
        "    type: uri_file\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python prepare-data.py \n",
        "  --input_data ${{inputs.input_data}}\n",
        "  --output_data ${{outputs.output_data}}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting prepare-data.yml\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train-model.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_model\n",
        "display_name: Train a linear, gradient boosting or random forest regression model\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "  training_data: \n",
        "    type: uri_file\n",
        "  algorithm:\n",
        "    type: string\n",
        "    default: 'linear-regression'\n",
        "  target_feature:\n",
        "    type: string\n",
        "    default: 'CPC'\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: mlflow_model\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "  python train-model.py \n",
        "  --training_data ${{inputs.training_data}} \n",
        "  --algorithm ${{inputs.algorithm}} \n",
        "  --target_feature ${{inputs.target}} \n",
        "  --model_output ${{outputs.model_output}} "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting train-model.yml\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "parent_dir = \"\"\n",
        "\n",
        "prep_data = load_component(source=parent_dir + \"./prepare-data.yml\")\n",
        "train_regression = load_component(source=parent_dir + \"./train-model.yml\")"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052163286
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def kw_CPC_prediction(pipeline_job_input,algorithm='linear-regression',target_feature='CPC'):\n",
        "    clean_data = prep_data(input_data=pipeline_job_input)\n",
        "    train_model = train_regression(training_data=clean_data.outputs.output_data,algorithm=algorithm,target_feature=target_feature)\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_transformed_data\": clean_data.outputs.output_data,\n",
        "        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n",
        "    }\n",
        "\n",
        "pipeline_job = kw_CPC_prediction(Input(type=AssetTypes.URI_FILE, path=\"azureml:kw-dataset:1\"))"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052333991
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "display_name: kw_CPC_prediction\ntype: pipeline\ninputs:\n  pipeline_job_input:\n    type: uri_file\n    path: azureml:kw-dataset:1\n  algorithm: linear-regression\n  target_feature: CPC\noutputs:\n  pipeline_job_transformed_data:\n    type: uri_file\n  pipeline_job_trained_model:\n    type: mlflow_model\njobs:\n  clean_data:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.inputs.pipeline_job_input}}\n    outputs:\n      output_data: ${{parent.outputs.pipeline_job_transformed_data}}\n    component:\n      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n      name: prep_data\n      version: '1'\n      display_name: Prepare training data\n      type: command\n      inputs:\n        input_data:\n          type: uri_file\n      outputs:\n        output_data:\n          type: uri_file\n      command: python prepare-data.py  --input_data ${{inputs.input_data}} --output_data\n        ${{outputs.output_data}}\n      environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n      code: azureml:/subscriptions/e1f27d73-68d8-4f59-900b-77783d4c5b3b/resourceGroups/End2EndCPC/providers/Microsoft.MachineLearningServices/workspaces/End2End_CPC/codes/1154ab57-c80b-4d5b-aa4e-28ddeaf5f669/versions/1\n      id: /subscriptions/e1f27d73-68d8-4f59-900b-77783d4c5b3b/resourceGroups/End2EndCPC/providers/Microsoft.MachineLearningServices/workspaces/End2End_CPC/components/azureml_anonymous/versions/9177857d-2fd9-475a-a0d1-17e946267475\n      is_deterministic: true\n  train_model:\n    type: command\n    inputs:\n      training_data:\n        path: ${{parent.jobs.clean_data.outputs.output_data}}\n      algorithm:\n        path: ${{parent.inputs.algorithm}}\n      target:\n        path: ${{parent.inputs.target_feature}}\n    outputs:\n      model_output: ${{parent.outputs.pipeline_job_trained_model}}\n    component:\n      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n      name: train_model\n      version: '1'\n      display_name: Train a linear, gradient boosting or random forest regression\n        model\n      type: command\n      inputs:\n        training_data:\n          type: uri_file\n        algorithm:\n          type: string\n          default: linear-regression\n        target:\n          type: string\n          default: CPC\n      outputs:\n        model_output:\n          type: mlflow_model\n      command: 'python train-model.py  --training_data ${{inputs.training_data}}  --algorithm\n        ${{inputs.algorithm}}  --target ${{inputs.target}}  --model_output ${{outputs.model_output}} '\n      environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n      code: azureml:/subscriptions/e1f27d73-68d8-4f59-900b-77783d4c5b3b/resourceGroups/End2EndCPC/providers/Microsoft.MachineLearningServices/workspaces/End2End_CPC/codes/1154ab57-c80b-4d5b-aa4e-28ddeaf5f669/versions/1\n      is_deterministic: true\n\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052334243
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "cpu_compute_target = \"aml-cluster\"\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"There is already a cluster named {cpu_compute_target}. Reusing it.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        type=\"amlcompute\",\n",
        "        size=\"STANDARD_DS11_V2\",\n",
        "        min_instances=0,\n",
        "        max_instances=2,\n",
        "        idle_time_before_scale_down=60,\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "There is already a cluster named aml-cluster. Reusing it.\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052334464
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "cluster_scale = AmlCompute(\n",
        "    name=\"aml-cluster\",\n",
        "    max_instances=2,\n",
        ")\n",
        "ml_client.begin_create_or_update(cluster_scale)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7f203164ea40>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052335319
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\n",
        "pipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"\n",
        "\n",
        "pipeline_job.settings.default_compute = \"aml-cluster\"\n",
        "\n",
        "pipeline_job.settings.default_datastore = \"workspaceblobstore\""
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052335513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submit job to workspace\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=\"pipeline_kw_CPC\"\n",
        ")\n",
        "pipeline_job"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "HttpResponseError",
          "evalue": "(UserError) Error occurred when loading YAML file rootNode, details: Parameter target defined in component definition has same name with reserved parameter, please change the name of this parameter.\nCode: UserError\nMessage: Error occurred when loading YAML file rootNode, details: Parameter target defined in component definition has same name with reserved parameter, please change the name of this parameter.\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"29a101c4faa5a410abc767f5e219254d\",\n        \"request\": \"07cf01eb62452820\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"francecentral\"\n}Type: Location\nInfo: {\n    \"value\": \"francecentral\"\n}Type: Time\nInfo: {\n    \"value\": \"2024-05-30T06:58:58.570307+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"BadArgument\",\n        \"innerError\": {\n            \"code\": \"ArgumentInvalid\",\n            \"innerError\": {\n                \"code\": \"YamlFileInvalid\",\n                \"innerError\": null\n            }\n        }\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# submit job to workspace\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline_kw_CPC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pipeline_job\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:609\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:541\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(job, raise_on_failure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_or_upload_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m git_props \u001b[38;5;241m=\u001b[39m get_git_properties()\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:890\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: Job) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;124;03m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_or_azureml_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_orchestrators\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_asset_arm_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;66;03m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_pipeline_job_inputs(job, job\u001b[38;5;241m.\u001b[39m_base_path)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:1115\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_arm_id_for_automl_job(job, resolver, inside_pipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(job, PipelineJob):\n\u001b[0;32m-> 1115\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_arm_id_for_pipeline_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon supported job type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(job)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:1230\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_pipeline_job\u001b[0;34m(self, pipeline_job, resolver)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;66;03m# Process each component job\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_component_operations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_dependencies_for_pipeline_component_jobs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComponentException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m   1235\u001b[0m         message\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[1;32m   1236\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m   1237\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mno_personal_data_message,\n\u001b[1;32m   1238\u001b[0m         error_category\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39merror_category,\n\u001b[1;32m   1239\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_component_operations.py:787\u001b[0m, in \u001b[0;36mComponentOperations._resolve_dependencies_for_pipeline_component_jobs\u001b[0;34m(self, component, resolver, resolve_inputs)\u001b[0m\n\u001b[1;32m    779\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon supported job type in Pipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(job_instance)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ComponentException(\n\u001b[1;32m    781\u001b[0m             message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    782\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mCOMPONENT,\n\u001b[1;32m    783\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    784\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    785\u001b[0m         )\n\u001b[0;32m--> 787\u001b[0m \u001b[43mcomponent_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_cache_utils.py:390\u001b[0m, in \u001b[0;36mCachedNodeResolver.resolve_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# release lock even if exception happens\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_cache_utils.py:354\u001b[0m, in \u001b[0;36mCachedNodeResolver._resolve_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_on_disk_cache_enabled() \u001b[38;5;129;01mand\u001b[39;00m is_private_preview_enabled():\n\u001b[1;32m    352\u001b[0m     cache_contents_to_resolve \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_cache_contents_from_disk(cache_contents_to_resolve)\n\u001b[0;32m--> 354\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_cache_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_contents_to_resolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill_back_component_to_nodes(dict_of_nodes_to_resolve)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_cache_utils.py:281\u001b[0m, in \u001b[0;36mCachedNodeResolver._resolve_cache_contents\u001b[0;34m(self, cache_contents_to_resolve, resolver)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(_map_func, cache_contents_to_resolve))\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_map_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_contents_to_resolve\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_cache_utils.py:267\u001b[0m, in \u001b[0;36mCachedNodeResolver._resolve_cache_contents.<locals>._map_func\u001b[0;34m(_cache_content)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_map_func\u001b[39m(_cache_content: _CacheContent):\n\u001b[0;32m--> 267\u001b[0m     _cache_content\u001b[38;5;241m.\u001b[39marm_id \u001b[38;5;241m=\u001b[39m \u001b[43mresolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cache_content\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponent_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mazureml_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAzureMLResourceType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOMPONENT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_on_disk_cache_enabled() \u001b[38;5;129;01mand\u001b[39;00m is_private_preview_enabled():\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_to_on_disk_cache(_cache_content\u001b[38;5;241m.\u001b[39mon_disk_hash, _cache_content\u001b[38;5;241m.\u001b[39marm_id)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:240\u001b[0m, in \u001b[0;36mOperationOrchestrator.get_asset_arm_id\u001b[0;34m(self, asset, azureml_type, register_asset, sub_workspace_resource)\u001b[0m\n\u001b[1;32m    238\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_arm_id(asset, register_asset\u001b[38;5;241m=\u001b[39mregister_asset)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m azureml_type \u001b[38;5;241m==\u001b[39m AzureMLResourceType\u001b[38;5;241m.\u001b[39mCOMPONENT \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asset, Component):\n\u001b[0;32m--> 240\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_component_arm_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported azureml type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for asset: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:374\u001b[0m, in \u001b[0;36mOperationOrchestrator._get_component_arm_id\u001b[0;34m(self, component)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"If component arm id is already resolved, return the id Or get arm id via remote call, register the component\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03mif necessary, and FILL BACK the arm id to component to reduce remote call.\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m component\u001b[38;5;241m.\u001b[39mid:\n\u001b[0;32m--> 374\u001b[0m     component\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_component\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_anonymous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m component\u001b[38;5;241m.\u001b[39mid\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:337\u001b[0m, in \u001b[0;36mmonitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_dimensions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(custom_dimensions \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[0;32m--> 337\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parameter_dimensions:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# collect from return if no dimensions from parameter\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         activityLogger\u001b[38;5;241m.\u001b[39mactivity_info\u001b[38;5;241m.\u001b[39mupdate(_collect_from_return_value(return_value))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_component_operations.py:401\u001b[0m, in \u001b[0;36mComponentOperations.create_or_update\u001b[0;34m(self, component, version, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m             result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version_operation\u001b[38;5;241m.\u001b[39mcreate_or_update(\n\u001b[1;32m    393\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    394\u001b[0m                 version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_args,\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[1;32m    404\u001b[0m     component \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(name\u001b[38;5;241m=\u001b[39mcomponent\u001b[38;5;241m.\u001b[39mname, version\u001b[38;5;241m=\u001b[39mcomponent\u001b[38;5;241m.\u001b[39mversion)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_component_operations.py:392\u001b[0m, in \u001b[0;36mComponentOperations.create_or_update\u001b[0;34m(self, component, version, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             result \u001b[38;5;241m=\u001b[39m _create_or_update_autoincrement(\n\u001b[1;32m    383\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    384\u001b[0m                 body\u001b[38;5;241m=\u001b[39mrest_component_resource,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_args,\n\u001b[1;32m    390\u001b[0m             )\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 392\u001b[0m             result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version_operation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m                \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m                \u001b[49m\u001b[43mresource_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrest_component_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2022_10_01/operations/_component_versions_operations.py:546\u001b[0m, in \u001b[0;36mComponentVersionsOperations.create_or_update\u001b[0;34m(self, resource_group_name, workspace_name, name, version, body, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[1;32m    545\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror, error_format\u001b[38;5;241m=\u001b[39mARMErrorFormat)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    549\u001b[0m     deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponentVersion\u001b[39m\u001b[38;5;124m'\u001b[39m, pipeline_response)\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (UserError) Error occurred when loading YAML file rootNode, details: Parameter target defined in component definition has same name with reserved parameter, please change the name of this parameter.\nCode: UserError\nMessage: Error occurred when loading YAML file rootNode, details: Parameter target defined in component definition has same name with reserved parameter, please change the name of this parameter.\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"29a101c4faa5a410abc767f5e219254d\",\n        \"request\": \"07cf01eb62452820\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"francecentral\"\n}Type: Location\nInfo: {\n    \"value\": \"francecentral\"\n}Type: Time\nInfo: {\n    \"value\": \"2024-05-30T06:58:58.570307+00:00\"\n}Type: InnerError\nInfo: {\n    \"value\": {\n        \"code\": \"BadArgument\",\n        \"innerError\": {\n            \"code\": \"ArgumentInvalid\",\n            \"innerError\": {\n                \"code\": \"YamlFileInvalid\",\n                \"innerError\": null\n            }\n        }\n    }\n}"
          ]
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717052337959
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}